{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7090de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Cell 1: Notebook Setup and Imports\n",
    "# ==================================\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to Python path so we can import config, signals, and backtest engine\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display options for easier debugging\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a8adec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Cell 2: Core Modules\n",
    "# ==================================\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253aa96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dolphindb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3161ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "<Exception> in run: Server response: 'select * from loadTable(\"dfs://rq_cn_futures_minute_Y\", \"k_minute\") where split(string(maturity_month), \".\")[1] in [\"01M\",\"05M\",\"09M\"] => Out of memory' script: '\nselect * from loadTable(\"dfs://rq_cn_futures_minute_Y\", \"k_minute\") \nwhere string(maturity_month).split(\".\")[1] in [\"01M\",\"05M\",\"09M\"]\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     13\u001b[39m ddb_query = \u001b[33m'''\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33mselect * from loadTable(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdfs://rq_cn_futures_minute_Y\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mk_minute\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m) \u001b[39m\n\u001b[32m     15\u001b[39m \u001b[33mwhere string(maturity_month).split(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m)[1] in [\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m01M\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m05M\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m09M\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m'''\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Run the query and get the result as a pandas DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m ddb_df = \u001b[43mddb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mddb_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Preview the data\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDolphinDB Soybean Oil (Y) contracts (Jan, May, Sep maturity months):\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/dolphindb/session.py:648\u001b[39m, in \u001b[36mSession.run\u001b[39m\u001b[34m(self, script, clearMemory, pickleTableToList, priority, parallelism, fetchSize, disableDecimal, *args)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fetchSize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BlockReader(\n\u001b[32m    640\u001b[39m         \u001b[38;5;28mself\u001b[39m.cpp.runBlock(\n\u001b[32m    641\u001b[39m             script,\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         )\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscript\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclearMemory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclearMemory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpickleTableToList\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickleTableToList\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparallelism\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparallelism\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisableDecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisableDecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: <Exception> in run: Server response: 'select * from loadTable(\"dfs://rq_cn_futures_minute_Y\", \"k_minute\") where split(string(maturity_month), \".\")[1] in [\"01M\",\"05M\",\"09M\"] => Out of memory' script: '\nselect * from loadTable(\"dfs://rq_cn_futures_minute_Y\", \"k_minute\") \nwhere string(maturity_month).split(\".\")[1] in [\"01M\",\"05M\",\"09M\"]\n'"
     ]
    }
   ],
   "source": [
    "# Connect to DolphinDB and run the specified query for Soybean Oil (Y) contracts\n",
    "\n",
    "# Define DolphinDB server credentials (placeholder values, update as needed)\n",
    "DDB_HOST = \"192.168.91.91\"\n",
    "DDB_PORT = 8848\n",
    "DDB_USER = \"admin\"\n",
    "DDB_PASSWORD = \"123456\"\n",
    "\n",
    "ddb = dolphindb.session()\n",
    "ddb.connect(DDB_HOST, DDB_PORT, DDB_USER, DDB_PASSWORD)\n",
    "\n",
    "# Compose the DolphinDB query\n",
    "ddb_query = '''\n",
    "select * from loadTable(\"dfs://rq_cn_futures_minute_Y\", \"k_minute\") \n",
    "where string(maturity_month).split(\".\")[1] in [\"01M\",\"05M\",\"09M\"]\n",
    "'''\n",
    "\n",
    "# Run the query and get the result as a pandas DataFrame\n",
    "ddb_df = ddb.run(ddb_query)\n",
    "\n",
    "# Preview the data\n",
    "print(\"DolphinDB Soybean Oil (Y) contracts (Jan, May, Sep maturity months):\")\n",
    "display(ddb_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb3db77",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/data_Y_1min.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Load each leg separately\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m leg1_df = \u001b[43mload_leg_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# e.g. Soybean Oil or 'Y'\u001b[39;00m\n\u001b[32m     27\u001b[39m leg2_df = load_leg_data(\u001b[33m\"\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# e.g. Soybean Meal or 'M'\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Preview\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mload_leg_data\u001b[39m\u001b[34m(leg_name)\u001b[39m\n\u001b[32m     16\u001b[39m filename = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleg_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_1min.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m path = data_dir / filename\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(df[\u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     21\u001b[39m df = df.sort_values(by=[\u001b[33m'\u001b[39m\u001b[33morder_book_id\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m'\u001b[39m]).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/data_Y_1min.csv'"
     ]
    }
   ],
   "source": [
    "# ==================================\n",
    "# Cell 3: Load Raw 1-min Futures Data for Both Legs Separately\n",
    "# ==================================\n",
    "\n",
    "def load_leg_data(leg_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads raw 1-minute futures data for a given leg from CSV in the ../data folder.\n",
    "\n",
    "    Parameters:\n",
    "        leg_name (str): Identifier for the futures leg (e.g., 'leg1', 'leg2' or 'Y', 'M')\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned and time-sorted tick data for the leg\n",
    "    \"\"\"\n",
    "    data_dir = Path(\"..\") / \"data\"\n",
    "    filename = f\"data_{leg_name}_1min.csv\"\n",
    "    path = data_dir / filename\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df = df.sort_values(by=['order_book_id', 'datetime']).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Load each leg separately\n",
    "leg1_df = load_leg_data(\"Y\")  # e.g. Soybean Oil or 'Y'\n",
    "leg2_df = load_leg_data(\"M\")  # e.g. Soybean Meal or 'M'\n",
    "\n",
    "# Preview\n",
    "print(\"Leg 1 Preview:\")\n",
    "display(leg1_df.head())\n",
    "print(\"\\nLeg 2 Preview:\")\n",
    "display(leg2_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Cell 4: Enrich Contract Metadata for Each Leg\n",
    "# ==================================\n",
    "\n",
    "import re\n",
    "\n",
    "def parse_contract_id(contract_id: str):\n",
    "    \"\"\"\n",
    "    Parses a contract ID of format 'PRODUCTYYYY' into product, year, and month.\n",
    "    E.g., 'M2001' → ('M', 2020, 1)\n",
    "    \"\"\"\n",
    "    match = re.match(r\"([A-Z]+)(\\d{4})\", contract_id)\n",
    "    if match:\n",
    "        product = match.group(1)\n",
    "        year = 2000 + int(match.group(2)[:2])   # '20' → 2020\n",
    "        month = int(match.group(2)[2:])         # '01' → 1 (January)\n",
    "        return product, year, month\n",
    "    return None, None, None\n",
    "\n",
    "def add_contract_metadata(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds parsed contract metadata columns: product, year, and month to a DataFrame\n",
    "    containing 'order_book_id'.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Raw leg data with 'order_book_id' column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Enriched DataFrame with contract metadata columns.\n",
    "    \"\"\"\n",
    "    parsed = df['order_book_id'].apply(parse_contract_id)\n",
    "    df[['product', 'year', 'month']] = pd.DataFrame(parsed.tolist(), index=df.index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714fada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leg 1 Metadata Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_book_id</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y2001</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>Y2003</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15480</th>\n",
       "      <td>Y2005</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38385</th>\n",
       "      <td>Y2007</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74280</th>\n",
       "      <td>Y2008</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_book_id product  year  month\n",
       "0             Y2001       Y  2020      1\n",
       "3330          Y2003       Y  2020      3\n",
       "15480         Y2005       Y  2020      5\n",
       "38385         Y2007       Y  2020      7\n",
       "74280         Y2008       Y  2020      8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Leg 2 Metadata Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_book_id</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2001</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>M2003</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15480</th>\n",
       "      <td>M2005</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38385</th>\n",
       "      <td>M2007</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74280</th>\n",
       "      <td>M2008</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      order_book_id product  year  month\n",
       "0             M2001       M  2020      1\n",
       "3330          M2003       M  2020      3\n",
       "15480         M2005       M  2020      5\n",
       "38385         M2007       M  2020      7\n",
       "74280         M2008       M  2020      8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================\n",
    "# Cell 5: Enrich leg1_df and leg2_df with product, year, month\n",
    "# ==================================\n",
    "\n",
    "leg1_df = add_contract_metadata(leg1_df)\n",
    "leg2_df = add_contract_metadata(leg2_df)\n",
    "\n",
    "# Preview enriched data\n",
    "print(\"Leg 1 Metadata Preview:\")\n",
    "display(leg1_df[['order_book_id', 'product', 'year', 'month']].drop_duplicates().head())\n",
    "\n",
    "print(\"\\nLeg 2 Metadata Preview:\")\n",
    "display(leg2_df[['order_book_id', 'product', 'year', 'month']].drop_duplicates().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faca934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leg 1 Contracts After Filtering:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_book_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y2001</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15480</th>\n",
       "      <td>Y2005</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118110</th>\n",
       "      <td>Y2009</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304560</th>\n",
       "      <td>Y2101</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459285</th>\n",
       "      <td>Y2105</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708975</th>\n",
       "      <td>Y2109</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958080</th>\n",
       "      <td>Y2201</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124070</th>\n",
       "      <td>Y2205</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371330</th>\n",
       "      <td>Y2209</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619850</th>\n",
       "      <td>Y2301</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        order_book_id  year  month\n",
       "0               Y2001  2020      1\n",
       "15480           Y2005  2020      5\n",
       "118110          Y2009  2020      9\n",
       "304560          Y2101  2021      1\n",
       "459285          Y2105  2021      5\n",
       "708975          Y2109  2021      9\n",
       "958080          Y2201  2022      1\n",
       "1124070         Y2205  2022      5\n",
       "1371330         Y2209  2022      9\n",
       "1619850         Y2301  2023      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Leg 2 Contracts After Filtering:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_book_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2001</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15480</th>\n",
       "      <td>M2005</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118110</th>\n",
       "      <td>M2009</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304560</th>\n",
       "      <td>M2101</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459285</th>\n",
       "      <td>M2105</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708975</th>\n",
       "      <td>M2109</td>\n",
       "      <td>2021</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958080</th>\n",
       "      <td>M2201</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124070</th>\n",
       "      <td>M2205</td>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371330</th>\n",
       "      <td>M2209</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619850</th>\n",
       "      <td>M2301</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        order_book_id  year  month\n",
       "0               M2001  2020      1\n",
       "15480           M2005  2020      5\n",
       "118110          M2009  2020      9\n",
       "304560          M2101  2021      1\n",
       "459285          M2105  2021      5\n",
       "708975          M2109  2021      9\n",
       "958080          M2201  2022      1\n",
       "1124070         M2205  2022      5\n",
       "1371330         M2209  2022      9\n",
       "1619850         M2301  2023      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================\n",
    "# Cell 6: Retain Only Jan, May, Sep Contracts\n",
    "# ==================================\n",
    "\n",
    "# Define valid expiry months\n",
    "valid_expiry_months = {1, 5, 9}\n",
    "\n",
    "def filter_valid_expiries(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the DataFrame to keep only contracts with expiry in Jan, May, or Sep.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Enriched leg data with 'month' column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with only valid expiry contracts.\n",
    "    \"\"\"\n",
    "    return df[df['month'].isin(valid_expiry_months)].copy()\n",
    "\n",
    "# Apply to each leg\n",
    "leg1_df = filter_valid_expiries(leg1_df)\n",
    "leg2_df = filter_valid_expiries(leg2_df)\n",
    "\n",
    "# Preview contract coverage\n",
    "print(\"Leg 1 Contracts After Filtering:\")\n",
    "display(leg1_df[['order_book_id', 'year', 'month']].drop_duplicates().sort_values(['year', 'month']).head(10))\n",
    "\n",
    "print(\"\\nLeg 2 Contracts After Filtering:\")\n",
    "display(leg2_df[['order_book_id', 'year', 'month']].drop_duplicates().sort_values(['year', 'month']).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2aeae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Cell 7: Utility to Compute Roll Dates\n",
    "# ==================================\n",
    "\n",
    "from calendar import monthrange\n",
    "\n",
    "def compute_scheduled_roll_date(year: int, month: int) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Computes scheduled roll date as the last calendar day of the month two months before expiry.\n",
    "    Used for defining the cut-off for stitched contract data, not the empirically observed last active date.\n",
    "    \"\"\"\n",
    "    if month <= 2:\n",
    "        roll_year = year - 1\n",
    "        roll_month = month + 10\n",
    "    else:\n",
    "        roll_year = year\n",
    "        roll_month = month - 2\n",
    "    last_day = monthrange(roll_year, roll_month)[1]\n",
    "    return pd.Timestamp(roll_year, roll_month, last_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eafce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_book_id</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>scheduled_roll_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y2001</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y2005</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y2009</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y2101</td>\n",
       "      <td>Y</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y2105</td>\n",
       "      <td>Y</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_book_id product  year  month scheduled_roll_date\n",
       "0         Y2001       Y  2020      1          2019-11-30\n",
       "1         Y2005       Y  2020      5          2020-03-31\n",
       "2         Y2009       Y  2020      9          2020-07-31\n",
       "3         Y2101       Y  2021      1          2020-11-30\n",
       "4         Y2105       Y  2021      5          2021-03-31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_book_id</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>scheduled_roll_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2001</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M2005</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2009</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>9</td>\n",
       "      <td>2020-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M2101</td>\n",
       "      <td>M</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M2105</td>\n",
       "      <td>M</td>\n",
       "      <td>2021</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-03-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_book_id product  year  month scheduled_roll_date\n",
       "0         M2001       M  2020      1          2019-11-30\n",
       "1         M2005       M  2020      5          2020-03-31\n",
       "2         M2009       M  2020      9          2020-07-31\n",
       "3         M2101       M  2021      1          2020-11-30\n",
       "4         M2105       M  2021      5          2021-03-31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================\n",
    "# Cell 8: Generate Contract Schedule with Roll Dates\n",
    "# ==================================\n",
    "\n",
    "def get_contract_schedule(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns contract schedule for a given leg with unique contracts.\n",
    "    Assumes df has already been filtered to desired expiry months.\n",
    "    \"\"\"\n",
    "    schedule = df[[\"order_book_id\", \"product\", \"year\", \"month\"]].drop_duplicates()\n",
    "    schedule[\"scheduled_roll_date\"] = schedule.apply(lambda row: compute_scheduled_roll_date(row.year, row.month), axis=1)\n",
    "    return schedule.sort_values([\"year\", \"month\"]).reset_index(drop=True)\n",
    "\n",
    "leg1_schedule = get_contract_schedule(leg1_df)\n",
    "display(leg1_schedule.head())\n",
    "leg2_schedule = get_contract_schedule(leg2_df)\n",
    "display(leg2_schedule.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6eae36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_book_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>trading_date</th>\n",
       "      <th>open_interest</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>total_turnover</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>parent_order_book_id</th>\n",
       "      <th>UTC_datetime</th>\n",
       "      <th>maturity_month</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>scheduled_roll_date</th>\n",
       "      <th>stitched_order_book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y2005</td>\n",
       "      <td>2020-01-02 09:01:00</td>\n",
       "      <td>2020.01.02</td>\n",
       "      <td>662395</td>\n",
       "      <td>6722</td>\n",
       "      <td>17735</td>\n",
       "      <td>1.193869e+09</td>\n",
       "      <td>6712</td>\n",
       "      <td>6746</td>\n",
       "      <td>6750</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020.01.02T01:01:00</td>\n",
       "      <td>2020.05M</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>Y2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y2005</td>\n",
       "      <td>2020-01-02 09:02:00</td>\n",
       "      <td>2020.01.02</td>\n",
       "      <td>662604</td>\n",
       "      <td>6746</td>\n",
       "      <td>6095</td>\n",
       "      <td>4.114961e+08</td>\n",
       "      <td>6746</td>\n",
       "      <td>6748</td>\n",
       "      <td>6756</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020.01.02T01:02:00</td>\n",
       "      <td>2020.05M</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>Y2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y2005</td>\n",
       "      <td>2020-01-02 09:03:00</td>\n",
       "      <td>2020.01.02</td>\n",
       "      <td>661900</td>\n",
       "      <td>6750</td>\n",
       "      <td>6516</td>\n",
       "      <td>4.393400e+08</td>\n",
       "      <td>6738</td>\n",
       "      <td>6746</td>\n",
       "      <td>6750</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020.01.02T01:03:00</td>\n",
       "      <td>2020.05M</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>Y2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y2005</td>\n",
       "      <td>2020-01-02 09:04:00</td>\n",
       "      <td>2020.01.02</td>\n",
       "      <td>661794</td>\n",
       "      <td>6746</td>\n",
       "      <td>3432</td>\n",
       "      <td>2.317446e+08</td>\n",
       "      <td>6744</td>\n",
       "      <td>6758</td>\n",
       "      <td>6758</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020.01.02T01:04:00</td>\n",
       "      <td>2020.05M</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>Y2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y2005</td>\n",
       "      <td>2020-01-02 09:05:00</td>\n",
       "      <td>2020.01.02</td>\n",
       "      <td>662319</td>\n",
       "      <td>6758</td>\n",
       "      <td>4491</td>\n",
       "      <td>3.035690e+08</td>\n",
       "      <td>6758</td>\n",
       "      <td>6760</td>\n",
       "      <td>6762</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020.01.02T01:05:00</td>\n",
       "      <td>2020.05M</td>\n",
       "      <td>Y</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>Y2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_book_id            datetime trading_date  open_interest  open  volume  total_turnover   low  close  high  \\\n",
       "0         Y2005 2020-01-02 09:01:00   2020.01.02         662395  6722   17735    1.193869e+09  6712   6746  6750   \n",
       "1         Y2005 2020-01-02 09:02:00   2020.01.02         662604  6746    6095    4.114961e+08  6746   6748  6756   \n",
       "2         Y2005 2020-01-02 09:03:00   2020.01.02         661900  6750    6516    4.393400e+08  6738   6746  6750   \n",
       "3         Y2005 2020-01-02 09:04:00   2020.01.02         661794  6746    3432    2.317446e+08  6744   6758  6758   \n",
       "4         Y2005 2020-01-02 09:05:00   2020.01.02         662319  6758    4491    3.035690e+08  6758   6760  6762   \n",
       "\n",
       "  parent_order_book_id         UTC_datetime maturity_month product  year  month scheduled_roll_date  \\\n",
       "0                    Y  2020.01.02T01:01:00       2020.05M       Y  2020      5          2020-03-31   \n",
       "1                    Y  2020.01.02T01:02:00       2020.05M       Y  2020      5          2020-03-31   \n",
       "2                    Y  2020.01.02T01:03:00       2020.05M       Y  2020      5          2020-03-31   \n",
       "3                    Y  2020.01.02T01:04:00       2020.05M       Y  2020      5          2020-03-31   \n",
       "4                    Y  2020.01.02T01:05:00       2020.05M       Y  2020      5          2020-03-31   \n",
       "\n",
       "  stitched_order_book_id  \n",
       "0                  Y2005  \n",
       "1                  Y2005  \n",
       "2                  Y2005  \n",
       "3                  Y2005  \n",
       "4                  Y2005  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_book_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>trading_date</th>\n",
       "      <th>open_interest</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>total_turnover</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>parent_order_book_id</th>\n",
       "      <th>UTC_datetime</th>\n",
       "      <th>maturity_month</th>\n",
       "      <th>product</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>scheduled_roll_date</th>\n",
       "      <th>stitched_order_book_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-01-02 09:01:00</td>\n",
       "      <td>2020.01.02</td>\n",
       "      <td>1688619</td>\n",
       "      <td>2780</td>\n",
       "      <td>20247</td>\n",
       "      <td>562833510.0</td>\n",
       "      <td>2778</td>\n",
       "      <td>2780</td>\n",
       "      <td>2782</td>\n",
       "      <td>M</td>\n",
       "      <td>2020.01.02T01:01:00</td>\n",
       "      <td>2020.05M</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>M2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-01-02 09:02:00</td>\n",
       "      <td>2020.01.02</td>\n",
       "      <td>1688123</td>\n",
       "      <td>2780</td>\n",
       "      <td>7854</td>\n",
       "      <td>218305110.0</td>\n",
       "      <td>2778</td>\n",
       "      <td>2779</td>\n",
       "      <td>2781</td>\n",
       "      <td>M</td>\n",
       "      <td>2020.01.02T01:02:00</td>\n",
       "      <td>2020.05M</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>M2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-01-02 09:03:00</td>\n",
       "      <td>2020.01.02</td>\n",
       "      <td>1688507</td>\n",
       "      <td>2779</td>\n",
       "      <td>6526</td>\n",
       "      <td>181441130.0</td>\n",
       "      <td>2779</td>\n",
       "      <td>2782</td>\n",
       "      <td>2783</td>\n",
       "      <td>M</td>\n",
       "      <td>2020.01.02T01:03:00</td>\n",
       "      <td>2020.05M</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>M2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-01-02 09:04:00</td>\n",
       "      <td>2020.01.02</td>\n",
       "      <td>1688491</td>\n",
       "      <td>2783</td>\n",
       "      <td>8699</td>\n",
       "      <td>242043320.0</td>\n",
       "      <td>2782</td>\n",
       "      <td>2784</td>\n",
       "      <td>2784</td>\n",
       "      <td>M</td>\n",
       "      <td>2020.01.02T01:04:00</td>\n",
       "      <td>2020.05M</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>M2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-01-02 09:05:00</td>\n",
       "      <td>2020.01.02</td>\n",
       "      <td>1688722</td>\n",
       "      <td>2783</td>\n",
       "      <td>12681</td>\n",
       "      <td>353090420.0</td>\n",
       "      <td>2783</td>\n",
       "      <td>2785</td>\n",
       "      <td>2786</td>\n",
       "      <td>M</td>\n",
       "      <td>2020.01.02T01:05:00</td>\n",
       "      <td>2020.05M</td>\n",
       "      <td>M</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>M2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_book_id            datetime trading_date  open_interest  open  volume  total_turnover   low  close  high  \\\n",
       "0         M2005 2020-01-02 09:01:00   2020.01.02        1688619  2780   20247     562833510.0  2778   2780  2782   \n",
       "1         M2005 2020-01-02 09:02:00   2020.01.02        1688123  2780    7854     218305110.0  2778   2779  2781   \n",
       "2         M2005 2020-01-02 09:03:00   2020.01.02        1688507  2779    6526     181441130.0  2779   2782  2783   \n",
       "3         M2005 2020-01-02 09:04:00   2020.01.02        1688491  2783    8699     242043320.0  2782   2784  2784   \n",
       "4         M2005 2020-01-02 09:05:00   2020.01.02        1688722  2783   12681     353090420.0  2783   2785  2786   \n",
       "\n",
       "  parent_order_book_id         UTC_datetime maturity_month product  year  month scheduled_roll_date  \\\n",
       "0                    M  2020.01.02T01:01:00       2020.05M       M  2020      5          2020-03-31   \n",
       "1                    M  2020.01.02T01:02:00       2020.05M       M  2020      5          2020-03-31   \n",
       "2                    M  2020.01.02T01:03:00       2020.05M       M  2020      5          2020-03-31   \n",
       "3                    M  2020.01.02T01:04:00       2020.05M       M  2020      5          2020-03-31   \n",
       "4                    M  2020.01.02T01:05:00       2020.05M       M  2020      5          2020-03-31   \n",
       "\n",
       "  stitched_order_book_id  \n",
       "0                  M2005  \n",
       "1                  M2005  \n",
       "2                  M2005  \n",
       "3                  M2005  \n",
       "4                  M2005  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================\n",
    "# Cell 9: Stitch Leg Based on Roll Schedule\n",
    "# ==================================\n",
    "\n",
    "def stitch_leg(df: pd.DataFrame, schedule: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Stitches a continuous intraday time series based on a roll schedule.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Cleaned 1-minute data for a single product.\n",
    "        schedule (pd.DataFrame): Roll schedule from get_contract_schedule().\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Stitched time series with 'stitched_order_book_id' tagging.\n",
    "    \"\"\"\n",
    "    stitched = []\n",
    "    for i, row in schedule.iterrows():\n",
    "        ob_id = row[\"order_book_id\"]\n",
    "        end_date = row[\"scheduled_roll_date\"]\n",
    "        start_date = schedule.iloc[i - 1][\"scheduled_roll_date\"] if i > 0 else None\n",
    "\n",
    "        leg_df = df[df[\"order_book_id\"] == ob_id].copy()\n",
    "\n",
    "        # Clip time range based on start and end of contract window\n",
    "        if start_date:\n",
    "            leg_df = leg_df[leg_df[\"datetime\"].dt.floor(\"D\") > start_date]\n",
    "        leg_df = leg_df[leg_df[\"datetime\"].dt.floor(\"D\") <= end_date]\n",
    "\n",
    "        if leg_df.empty:\n",
    "            continue\n",
    "\n",
    "        leg_df = leg_df.sort_values(\"datetime\")  # critical for any resampling/sync\n",
    "        leg_df[\"scheduled_roll_date\"] = end_date\n",
    "        leg_df[\"stitched_order_book_id\"] = ob_id\n",
    "        stitched.append(leg_df)\n",
    "\n",
    "    return pd.concat(stitched).sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "stitched_leg1 = stitch_leg(leg1_df, leg1_schedule)\n",
    "display(stitched_leg1.head())\n",
    "stitched_leg2 = stitch_leg(leg2_df, leg2_schedule)\n",
    "display(stitched_leg2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe823ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>trade_date</th>\n",
       "      <th>gap_days_to_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02 09:01:00</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02 09:02:00</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02 09:03:00</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02 09:04:00</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02 09:05:00</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime trade_date  gap_days_to_next\n",
       "0 2020-01-02 09:01:00 2020-01-02               1.0\n",
       "1 2020-01-02 09:02:00 2020-01-02               1.0\n",
       "2 2020-01-02 09:03:00 2020-01-02               1.0\n",
       "3 2020-01-02 09:04:00 2020-01-02               1.0\n",
       "4 2020-01-02 09:05:00 2020-01-02               1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================\n",
    "# Cell 10: Merge Legs and Compute gap_days_to_next\n",
    "# ==================================\n",
    "\n",
    "def compute_gap_days_to_next(merged_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute calendar-day gap to the next trade date and merge into merged_df.\n",
    "    Adds 'gap_days_to_next' column based on 'datetime' column normalized to date.\n",
    "    \"\"\"\n",
    "    # Step 1: Extract unique trade dates\n",
    "    df_day = merged_df[[\"datetime\"]].copy()\n",
    "    df_day[\"trade_date\"] = df_day[\"datetime\"].dt.normalize()\n",
    "    df_day = df_day.drop_duplicates(\"trade_date\").sort_values(\"trade_date\").reset_index(drop=True)\n",
    "\n",
    "    # Step 2: Compute gap to next trade date\n",
    "    df_day[\"next_trade_date\"] = df_day[\"trade_date\"].shift(-1)\n",
    "    df_day[\"gap_days_to_next\"] = (df_day[\"next_trade_date\"] - df_day[\"trade_date\"]).dt.days\n",
    "    df_day[\"gap_days_to_next\"] = df_day[\"gap_days_to_next\"].fillna(np.inf)\n",
    "\n",
    "    # Step 3: Merge gap info back into full merged_df\n",
    "    merged_df[\"trade_date\"] = merged_df[\"datetime\"].dt.normalize()\n",
    "    merged_df = merged_df.merge(\n",
    "        df_day[[\"trade_date\", \"gap_days_to_next\"]],\n",
    "        on=\"trade_date\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# Step 1: Merge both legs on timestamp using merge_asof with 30s tolerance\n",
    "merged_df = pd.merge_asof(\n",
    "    stitched_leg1.sort_values(\"datetime\"),\n",
    "    stitched_leg2.sort_values(\"datetime\"),\n",
    "    on=\"datetime\",\n",
    "    direction=\"nearest\",\n",
    "    tolerance=pd.Timedelta(seconds=30),\n",
    "    suffixes=(\"_1\", \"_2\")  # ✅ avoid _x/_y\n",
    ")\n",
    "\n",
    "# Step 2: Compute and attach gap_days_to_next\n",
    "merged_df = compute_gap_days_to_next(merged_df)\n",
    "\n",
    "# Optional preview\n",
    "display(merged_df[[\"datetime\", \"trade_date\", \"gap_days_to_next\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639eedac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>contract_1</th>\n",
       "      <th>contract_2</th>\n",
       "      <th>actual_roll_date_1</th>\n",
       "      <th>actual_roll_date_2</th>\n",
       "      <th>roll_date_mismatch</th>\n",
       "      <th>is_roll_date_1</th>\n",
       "      <th>is_roll_date_2</th>\n",
       "      <th>contract_pair_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-02 09:01:00</td>\n",
       "      <td>Y2005</td>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02 09:02:00</td>\n",
       "      <td>Y2005</td>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-02 09:03:00</td>\n",
       "      <td>Y2005</td>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-02 09:04:00</td>\n",
       "      <td>Y2005</td>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-02 09:05:00</td>\n",
       "      <td>Y2005</td>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-02 09:06:00</td>\n",
       "      <td>Y2005</td>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-02 09:07:00</td>\n",
       "      <td>Y2005</td>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-02 09:08:00</td>\n",
       "      <td>Y2005</td>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-02 09:09:00</td>\n",
       "      <td>Y2005</td>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-02 09:10:00</td>\n",
       "      <td>Y2005</td>\n",
       "      <td>M2005</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime contract_1 contract_2 actual_roll_date_1 actual_roll_date_2  roll_date_mismatch  is_roll_date_1  \\\n",
       "0 2020-01-02 09:01:00      Y2005      M2005         2020-03-31         2020-03-31               False           False   \n",
       "1 2020-01-02 09:02:00      Y2005      M2005         2020-03-31         2020-03-31               False           False   \n",
       "2 2020-01-02 09:03:00      Y2005      M2005         2020-03-31         2020-03-31               False           False   \n",
       "3 2020-01-02 09:04:00      Y2005      M2005         2020-03-31         2020-03-31               False           False   \n",
       "4 2020-01-02 09:05:00      Y2005      M2005         2020-03-31         2020-03-31               False           False   \n",
       "5 2020-01-02 09:06:00      Y2005      M2005         2020-03-31         2020-03-31               False           False   \n",
       "6 2020-01-02 09:07:00      Y2005      M2005         2020-03-31         2020-03-31               False           False   \n",
       "7 2020-01-02 09:08:00      Y2005      M2005         2020-03-31         2020-03-31               False           False   \n",
       "8 2020-01-02 09:09:00      Y2005      M2005         2020-03-31         2020-03-31               False           False   \n",
       "9 2020-01-02 09:10:00      Y2005      M2005         2020-03-31         2020-03-31               False           False   \n",
       "\n",
       "   is_roll_date_2  contract_pair_group  \n",
       "0           False                    1  \n",
       "1           False                    1  \n",
       "2           False                    1  \n",
       "3           False                    1  \n",
       "4           False                    1  \n",
       "5           False                    1  \n",
       "6           False                    1  \n",
       "7           False                    1  \n",
       "8           False                    1  \n",
       "9           False                    1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================\n",
    "# Cell 11: Enrich merged_df with Contract Info and Roll Detection\n",
    "# ==================================\n",
    "\n",
    "# Step 1: Rename for clarity\n",
    "merged_df = merged_df.rename(columns={\n",
    "    \"stitched_order_book_id_1\": \"contract_1\",\n",
    "    \"stitched_order_book_id_2\": \"contract_2\"\n",
    "})\n",
    "\n",
    "# Step 2: Compute actual roll date = last datetime seen per contract\n",
    "actual_roll_1 = (\n",
    "    merged_df.groupby(\"contract_1\", observed=True)[\"datetime\"]\n",
    "    .max().dt.floor(\"D\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"datetime\": \"actual_roll_date_1\"})\n",
    ")\n",
    "\n",
    "actual_roll_2 = (\n",
    "    merged_df.groupby(\"contract_2\", observed=True)[\"datetime\"]\n",
    "    .max().dt.floor(\"D\")\n",
    "    .reset_index()\n",
    "    .rename(columns={\"datetime\": \"actual_roll_date_2\"})\n",
    ")\n",
    "\n",
    "# Step 3: Merge actual roll dates\n",
    "merged_df = merged_df.merge(actual_roll_1, on=\"contract_1\", how=\"left\")\n",
    "merged_df = merged_df.merge(actual_roll_2, on=\"contract_2\", how=\"left\")\n",
    "\n",
    "# Step 4: Define is_roll_date flags per leg\n",
    "merged_df[\"is_roll_date_1\"] = merged_df[\"datetime\"].dt.floor(\"D\") == merged_df[\"actual_roll_date_1\"]\n",
    "merged_df[\"is_roll_date_2\"] = merged_df[\"datetime\"].dt.floor(\"D\") == merged_df[\"actual_roll_date_2\"]\n",
    "\n",
    "# Step 5: Assign group id based on either contract changing (robust leg pairing)\n",
    "merged_df[\"contract_pair_group\"] = (\n",
    "    merged_df[[\"contract_1\", \"contract_2\"]] != merged_df[[\"contract_1\", \"contract_2\"]].shift()\n",
    ").any(axis=1).cumsum()\n",
    "\n",
    "# Step 6: Flag roll mismatches based on is_roll_date_1 vs is_roll_date_2\n",
    "roll_mismatch_mask = merged_df[\"is_roll_date_1\"] ^ merged_df[\"is_roll_date_2\"]\n",
    "n_mismatches = roll_mismatch_mask.sum()\n",
    "\n",
    "if n_mismatches > 0:\n",
    "    print(f\"⚠️ Warning: {n_mismatches} mismatched roll dates found (only one leg rolled).\")\n",
    "    print(\"🧠 These are handled via spread groupings (contract_pair_group).\")\n",
    "\n",
    "# Optional: Store for inspection\n",
    "merged_df[\"roll_date_mismatch\"] = roll_mismatch_mask\n",
    "\n",
    "# Preview key fields\n",
    "preview_cols = [\n",
    "    \"datetime\", \"contract_1\", \"contract_2\",\n",
    "    \"actual_roll_date_1\", \"actual_roll_date_2\", \"roll_date_mismatch\",\n",
    "    \"is_roll_date_1\", \"is_roll_date_2\", \"contract_pair_group\"\n",
    "]\n",
    "display(merged_df[preview_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Cell 12: Compute Price Ratio and Log Price Ratio\n",
    "# ==================================\n",
    "\n",
    "# Step 1: Basic validation (optional but safe)\n",
    "if not {\"close_1\", \"close_2\"}.issubset(merged_df.columns):\n",
    "    raise ValueError(\"Missing close_1 or close_2 columns for price ratio computation.\")\n",
    "\n",
    "# Step 2: Compute price ratio and log price ratio\n",
    "merged_df[\"price_ratio\"] = merged_df[\"close_1\"] / merged_df[\"close_2\"]\n",
    "merged_df[\"log_price_ratio\"] = np.log(merged_df[\"close_1\"]) - np.log(merged_df[\"close_2\"])\n",
    "\n",
    "# Step 3: Preview\n",
    "preview_cols = [\n",
    "    \"datetime\", \"contract_1\", \"contract_2\",\n",
    "    \"close_1\", \"close_2\",\n",
    "    \"price_ratio\", \"log_price_ratio\",\n",
    "    \"contract_pair_group\"\n",
    "]\n",
    "display(merged_df[preview_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0230a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Cell 13: Import Parameter Grid and Metrics\n",
    "# ==================================\n",
    "\n",
    "# Then import config\n",
    "from config.config_params import param_grid, evaluation_metrics\n",
    "\n",
    "print(f\"Total parameter combinations: {len(param_grid)}\")\n",
    "from pprint import pprint\n",
    "pprint(param_grid[:3])\n",
    "\n",
    "# Inspect keys of one sample config\n",
    "print(\"Sample keys:\")\n",
    "print(param_grid[0].keys())\n",
    "print(\"Signal config:\", param_grid[0]['signal'])\n",
    "print(\"Execution config:\", param_grid[0]['execution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab05091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Cell 14: Define run_backtest_for_config Function\n",
    "# ==================================\n",
    "\"\"\"\n",
    "This helper function takes a merged minute-level DataFrame and a configuration (config) dictionary containing signal and execution parameters,\n",
    "runs the signal generation + backtest loop + metrics, and returns results.\n",
    "\"\"\"\n",
    "\n",
    "from spread_backtest_engine import (\n",
    "    compute_rolling_zscore_grouped,\n",
    "    run_backtest_loop,\n",
    "    compute_trading_metrics\n",
    ")\n",
    "\n",
    "from signals.signal_generators import generate_trading_signals_directional\n",
    "\n",
    "def run_backtest_for_config(merged_df, config):\n",
    "    \"\"\"\n",
    "    Run full pipeline for a single parameter config.\n",
    "\n",
    "    Parameters:\n",
    "        merged_df (pd.DataFrame): Merged data with price columns, already preprocessed\n",
    "        config (dict): Dict with 'signal' and 'execution' sub-dicts\n",
    "\n",
    "    Returns:\n",
    "        dict: Contains config, metrics, df_result, trade_data\n",
    "    \"\"\"\n",
    "    signal_params = config[\"signal\"]\n",
    "    exec_params = config[\"execution\"]\n",
    "    zscore_window = signal_params[\"zscore_window\"]\n",
    "\n",
    "    # 1. Compute rolling z-score on log price ratio\n",
    "    assert \"log_price_ratio\" in merged_df.columns, \"Missing log_price_ratio column\"\n",
    "    merged_df[\"zscore\"] = compute_rolling_zscore_grouped(\n",
    "        merged_df,\n",
    "        value_col=\"log_price_ratio\",\n",
    "        window=zscore_window,\n",
    "        group_col=f\"contract_pair_group\" # groups based on generic pair change, not specific contract codes\n",
    "    )\n",
    "\n",
    "    # 2. Generate trading signals\n",
    "    merged_df[\"position_signal\"], merged_df[\"raw_signal\"] = generate_trading_signals_directional(\n",
    "        merged_df[\"zscore\"],\n",
    "        entry_threshold_long=signal_params[\"entry_threshold_long\"],\n",
    "        entry_threshold_short=signal_params[\"entry_threshold_short\"],\n",
    "        exit_threshold_long=signal_params[\"exit_threshold_long\"],\n",
    "        exit_threshold_short=signal_params[\"exit_threshold_short\"]\n",
    "    )\n",
    "\n",
    "    # 3. Run backtest loop\n",
    "    df_result, trade_data = run_backtest_loop(\n",
    "        merged_df,\n",
    "        signal_col=\"raw_signal\",\n",
    "        execution_config=exec_params\n",
    "    )\n",
    "\n",
    "    # 4. Derive trade directions for metrics\n",
    "    if df_result[\"trade_id\"].notna().any():\n",
    "        trade_directions = (\n",
    "            df_result[df_result[\"trade_id\"].notna()]\n",
    "            .groupby(\"trade_id\", observed=True)[\"executed_position\"]\n",
    "            .first()\n",
    "            .astype(int)\n",
    "            .tolist()\n",
    "        )\n",
    "    else:\n",
    "        trade_directions = []\n",
    "\n",
    "    # 5. Compute trading metrics\n",
    "    metrics = compute_trading_metrics(df_result, trade_data, trade_directions)\n",
    "\n",
    "    return {\n",
    "        \"config\": config,\n",
    "        \"metrics\": metrics,\n",
    "        \"df_result\": df_result,\n",
    "        \"trade_data\": trade_data\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad621f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Cell 15: Helper — Optimize Config on Training Group\n",
    "# =============================================\n",
    "\"\"\"\n",
    "This function runs a grid search over the parameter grid on a given training group (train_df),\n",
    "evaluates each config using specified trading metrics, ranks them, and returns the best configuration.\n",
    "\n",
    "It ensures:\n",
    "- All configs are attempted robustly with exception handling.\n",
    "- Metric-based ranking that supports multiple objective metrics.\n",
    "- Raw config and per-metric details are retained for full traceability.\n",
    "\"\"\"\n",
    "\n",
    "def optimize_config_on_group(train_df, param_grid, evaluation_metrics):\n",
    "    # Run Grid Search Over Parameter Grid\n",
    "    grid_results = []\n",
    "\n",
    "    for config in param_grid:\n",
    "        try:\n",
    "            result = run_backtest_for_config(train_df.copy(), config)\n",
    "            grid_results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error with config: {config}\")\n",
    "            print(e)\n",
    "\n",
    "    if not grid_results:\n",
    "        raise ValueError(\"No successful backtest runs in training group.\")\n",
    "\n",
    "    # Flatten results into DataFrame\n",
    "    results_records = []\n",
    "    for res in grid_results:\n",
    "        record = {\n",
    "            \"config\": res[\"config\"],  # Preserve raw config dict\n",
    "            **res[\"config\"][\"signal\"],  # Flatten signal params\n",
    "            **res[\"config\"][\"execution\"],  # Flatten execution params\n",
    "            **res[\"metrics\"]  # Add performance metrics\n",
    "        }\n",
    "        results_records.append(record)\n",
    "    results_df = pd.DataFrame(results_records)\n",
    "\n",
    "    # Rank-based voting across all specified metrics\n",
    "    ranked_df = results_df.copy()\n",
    "    for metric, higher_is_better in evaluation_metrics:\n",
    "        ascending = not higher_is_better\n",
    "        ranked_df[f\"{metric}_rank\"] = ranked_df[metric].rank(\n",
    "            ascending=ascending, method=\"min\"\n",
    "        )\n",
    "\n",
    "    # Sum of ranks = total rank score (lower is better)\n",
    "    rank_cols = [f\"{metric}_rank\" for metric, _ in evaluation_metrics]\n",
    "    ranked_df[\"total_rank_score\"] = ranked_df[rank_cols].sum(axis=1)\n",
    "    ranked_df = ranked_df.sort_values(\"total_rank_score\").reset_index(drop=True)\n",
    "\n",
    "    # Select best config and its metrics\n",
    "    best_config = ranked_df.loc[0, \"config\"]\n",
    "    best_metrics = ranked_df.loc[0, [m for m, _ in evaluation_metrics]].to_dict()\n",
    "\n",
    "    return best_config, ranked_df, best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Cell 16: Walk-Forward Execution — Grouping, Snapshot, Evaluation Loop\n",
    "# ================================================================\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "# === Step 1: Identify Stitched Contract Groups (generic leg version) ===\n",
    "group_ids = sorted(merged_df[\"contract_pair_group\"].unique())\n",
    "print(f\"🔢 Found {len(group_ids)} stitched contract groups: {group_ids}\")\n",
    "\n",
    "# === Step 2: Create Timestamped Folder to Save Run Outputs ===\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "run_folder = os.path.join(project_root, \"backtest_runs\", \"walkforward_runs\", timestamp)\n",
    "os.makedirs(run_folder, exist_ok=True)\n",
    "print(f\"📂 Saving walk-forward outputs to: {run_folder}\")\n",
    "\n",
    "# === Step 3: Snapshot Config and Signal Generator Files ===\n",
    "config_src = os.path.join(project_root, \"config\", \"config_params.py\")\n",
    "config_dst = os.path.join(run_folder, \"config_params_snapshot.py\")\n",
    "shutil.copy(config_src, config_dst)\n",
    "\n",
    "signal_src = os.path.join(project_root, \"signals\", \"signal_generators.py\")\n",
    "signal_dst = os.path.join(run_folder, \"signal_generators_snapshot.py\")\n",
    "shutil.copy(signal_src, signal_dst)\n",
    "\n",
    "# === Step 4: Walk-Forward Loop with Optimization and Backtest ===\n",
    "walkforward_summary = []\n",
    "all_walkforward_df_results = []\n",
    "all_walkforward_trade_data = []\n",
    "\n",
    "for i in tqdm(range(1, len(group_ids)), desc=\"Walk-Forward Iterations\"):\n",
    "    train_group = group_ids[i - 1]\n",
    "    test_group = group_ids[i]\n",
    "\n",
    "    print(f\"\\n▶️ Walk-forward iteration: Train on group {train_group}, test on group {test_group}\")\n",
    "\n",
    "    train_df = merged_df[merged_df[\"contract_pair_group\"] == train_group].copy()\n",
    "    test_df = merged_df[merged_df[\"contract_pair_group\"] == test_group].copy()\n",
    "\n",
    "    if train_df.empty or test_df.empty:\n",
    "        print(f\"⚠️ Skipping group {test_group} due to empty train/test split.\")\n",
    "        continue\n",
    "\n",
    "    # === Step 4.1: Optimize on training group ===\n",
    "    best_config, ranked_df_train, best_train_metrics = optimize_config_on_group(\n",
    "        train_df, param_grid, evaluation_metrics\n",
    "    )\n",
    "    print(\"✅ Selected config:\")\n",
    "    pprint(best_config)\n",
    "\n",
    "    # === Step 4.2: Run backtest on test group with best config ===\n",
    "    test_result = run_backtest_for_config(test_df.copy(), best_config)\n",
    "\n",
    "    # Collect results and trade data for stitching\n",
    "    all_walkforward_df_results.append(test_result[\"df_result\"])\n",
    "    all_walkforward_trade_data.append(test_result[\"trade_data\"])\n",
    "\n",
    "    # Store summary metrics\n",
    "    walkforward_summary.append({\n",
    "        \"train_group\": train_group,\n",
    "        \"test_group\": test_group,\n",
    "        \"best_config\": best_config,\n",
    "        \"train_metrics\": best_train_metrics,\n",
    "        \"test_metrics\": test_result[\"metrics\"],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d546bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# Cell 17: Ensure Global Trade ID Uniqueness Across Groups\n",
    "# =====================================================\n",
    "\n",
    "trade_id_offset = 0\n",
    "\n",
    "# Patch all_walkforward_df_results to ensure unique trade_id\n",
    "for df_result in all_walkforward_df_results:\n",
    "    if \"trade_id\" in df_result.columns:\n",
    "        mask = df_result[\"trade_id\"].notna()\n",
    "        df_result.loc[mask, \"trade_id\"] += trade_id_offset\n",
    "        trade_id_offset += df_result.loc[mask, \"trade_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12685693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# Cell 18: Aggregate Walk-Forward Results and Compute Final Metrics\n",
    "# ====================================================================\n",
    "\n",
    "# === Step 1: Concatenate all walkforward group-level df_results ===\n",
    "combined_df_result = pd.concat(all_walkforward_df_results, ignore_index=True)\n",
    "combined_df_result = combined_df_result.sort_values(\"datetime\").reset_index(drop=True)\n",
    "\n",
    "# === Step 2: Concatenate all trade-level data ===\n",
    "combined_trade_data = {\n",
    "    \"entry_times\": [],\n",
    "    \"exit_times\": [],\n",
    "    \"trade_real_returns\": [],\n",
    "    \"holding_durations\": [],\n",
    "    # Add more fields here if necessary\n",
    "}\n",
    "\n",
    "for td in all_walkforward_trade_data:\n",
    "    for key in combined_trade_data:\n",
    "        if key in td:\n",
    "            combined_trade_data[key].extend(td[key])\n",
    "\n",
    "# === Step 3: Compute trade directions based on first executed_position per trade_id ===\n",
    "if \"trade_id\" in combined_df_result.columns and combined_df_result[\"trade_id\"].notna().any():\n",
    "    trade_directions = (\n",
    "        combined_df_result[combined_df_result[\"trade_id\"].notna()]\n",
    "        .groupby(\"trade_id\", observed=True)[\"executed_position\"]\n",
    "        .first()\n",
    "        .astype(int)\n",
    "        .tolist()\n",
    "    )\n",
    "else:\n",
    "    trade_directions = []\n",
    "\n",
    "# === Step 4: Compute final metrics ===\n",
    "final_metrics = compute_trading_metrics(combined_df_result, combined_trade_data, trade_directions)\n",
    "\n",
    "# === Step 5: Print Summary ===\n",
    "print(\"\\n✅ Aggregated Walk-Forward Metrics:\")\n",
    "for k, v in final_metrics.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"{k:<30}: {v:,.4f}\")\n",
    "    else:\n",
    "        print(f\"{k:<30}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# Cell 19: Plot Aggregated Equity Curve with Key Annotations\n",
    "# ================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# === Step 1: Compute equity curve using real returns ===\n",
    "combined_df_result[\"equity_curve\"] = (1 + combined_df_result[\"strategy_real_return\"]).cumprod()\n",
    "\n",
    "# === Step 2: Extract max drawdown and largest single-bar drop points ===\n",
    "max_drawdown_time = final_metrics[\"date_of_max_drawdown\"]\n",
    "max_drop_idx = combined_df_result[\"strategy_log_return\"].idxmin()\n",
    "max_drop_time = combined_df_result.loc[max_drop_idx, \"datetime\"]\n",
    "\n",
    "# === Step 3: Identify contract group boundary transitions ===\n",
    "contract_boundaries = (\n",
    "    combined_df_result[[\"datetime\", \"contract_pair_group\"]]\n",
    "    .drop_duplicates(\"contract_pair_group\")\n",
    "    .sort_values(\"datetime\")\n",
    ")\n",
    "\n",
    "# === Step 4: Plot ===\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "# Plot equity curve\n",
    "ax.plot(\n",
    "    combined_df_result[\"datetime\"],\n",
    "    combined_df_result[\"equity_curve\"],\n",
    "    label=\"Equity Curve\",\n",
    "    color=\"royalblue\",\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "# Annotate max drawdown\n",
    "ax.axvline(max_drawdown_time, color=\"firebrick\", linestyle=\"--\", alpha=0.8, linewidth=1)\n",
    "ax.annotate(\"Max Drawdown\",\n",
    "            xy=(max_drawdown_time, combined_df_result.loc[combined_df_result[\"datetime\"] == max_drawdown_time, \"equity_curve\"]),\n",
    "            xytext=(0, -30), textcoords=\"offset points\",\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"firebrick\"),\n",
    "            ha='center', color=\"firebrick\", fontsize=9)\n",
    "\n",
    "# Annotate largest single-period drop\n",
    "ax.axvline(max_drop_time, color=\"darkorange\", linestyle=\"--\", alpha=0.8, linewidth=1)\n",
    "ax.annotate(\"Largest Drop\",\n",
    "            xy=(max_drop_time, combined_df_result.loc[max_drop_idx, \"equity_curve\"]),\n",
    "            xytext=(0, 30), textcoords=\"offset points\",\n",
    "            arrowprops=dict(arrowstyle=\"->\", color=\"darkorange\"),\n",
    "            ha='center', color=\"darkorange\", fontsize=9)\n",
    "\n",
    "# Vertical lines for each contract group boundary\n",
    "for _, row in contract_boundaries.iterrows():\n",
    "    ax.axvline(row[\"datetime\"], color=\"slategray\", linestyle=\"--\", linewidth=0.8, alpha=0.6)\n",
    "\n",
    "# Plot aesthetics\n",
    "ax.set_title(\"Aggregated Walk-Forward Equity Curve with Key Markers\", fontsize=14)\n",
    "ax.set_ylabel(\"Equity Curve\", fontsize=12)\n",
    "ax.set_xlabel(\"Datetime\", fontsize=12)\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "# Improve x-axis formatting\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "plt.grid(True, linestyle='--', linewidth=0.3, alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save to run folder\n",
    "fig.savefig(os.path.join(run_folder, \"equity_curve.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ceeccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Cell 20: Construct walkforward_df from walkforward_summary\n",
    "# ==================================\n",
    "\n",
    "walkforward_records = []\n",
    "\n",
    "for entry in walkforward_summary:\n",
    "    flat_record = {\n",
    "        \"train_group\": entry[\"train_group\"],\n",
    "        \"test_group\": entry[\"test_group\"],\n",
    "    }\n",
    "\n",
    "    # Flatten training metrics\n",
    "    for k, v in entry[\"train_metrics\"].items():\n",
    "        flat_record[f\"train_{k}\"] = v\n",
    "\n",
    "    # Flatten test metrics\n",
    "    for k, v in entry[\"test_metrics\"].items():\n",
    "        flat_record[f\"test_{k}\"] = v\n",
    "\n",
    "    # Optional: Flatten config for diagnostics\n",
    "    for k, v in entry[\"best_config\"][\"signal\"].items():\n",
    "        flat_record[f\"config_{k}\"] = v\n",
    "    for k, v in entry[\"best_config\"][\"execution\"].items():\n",
    "        flat_record[f\"config_{k}\"] = v\n",
    "\n",
    "    walkforward_records.append(flat_record)\n",
    "\n",
    "# Convert to DataFrame\n",
    "walkforward_df = pd.DataFrame(walkforward_records)\n",
    "\n",
    "print(f\"\\n✅ Constructed walkforward_df with shape: {walkforward_df.shape}\")\n",
    "display(walkforward_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dcab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Cell 21: Save walk-forward outputs to run_folder\n",
    "# ==================================\n",
    "\n",
    "# 1. Save combined result DataFrame\n",
    "combined_df_result.to_csv(os.path.join(run_folder, \"combined_df_result.csv\"), index=False)\n",
    "\n",
    "# 2. Save combined trade data as pickle\n",
    "with open(os.path.join(run_folder, \"combined_trade_data.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(combined_trade_data, f)\n",
    "\n",
    "# 3. Save final aggregated metrics as JSON (datetime-safe)\n",
    "with open(os.path.join(run_folder, \"final_metrics.json\"), \"w\") as f:\n",
    "    json.dump(final_metrics, f, indent=2, default=str)\n",
    "\n",
    "# 4. Save raw walkforward summary\n",
    "with open(os.path.join(run_folder, \"walkforward_summary.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(walkforward_summary, f)\n",
    "\n",
    "# 5. Save flattened summary table\n",
    "walkforward_df.to_csv(os.path.join(run_folder, \"walkforward_df.csv\"), index=False)\n",
    "\n",
    "print(\"\\n✅ Saved all aggregated outputs to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a55ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================\n",
    "# Cell 22: Plot Train vs Test Metric Stability across groups\n",
    "# ==================================\n",
    "\n",
    "import seaborn as sns\n",
    "from config.config_params import base_metrics\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "n_rows = len(base_metrics)\n",
    "fig, axes = plt.subplots(n_rows, 1, figsize=(10, 3 * n_rows), sharex=True)\n",
    "\n",
    "x = range(len(walkforward_df))\n",
    "\n",
    "for i, metric in enumerate(base_metrics):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot both train and test curves\n",
    "    sns.lineplot(x=x, y=walkforward_df[f\"train_{metric}\"], marker=\"o\", label=\"Train\", ax=ax)\n",
    "    sns.lineplot(x=x, y=walkforward_df[f\"test_{metric}\"], marker=\"o\", label=\"Test\", ax=ax)\n",
    "    \n",
    "    ax.set_ylabel(metric.replace(\"_\", \" \").title())\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(walkforward_df[\"test_group\"], rotation=0)\n",
    "    ax.set_title(f\"Train vs Test {metric.replace('_', ' ').title()}\")\n",
    "    ax.axhline(0, color=\"black\", linestyle=\"--\", linewidth=0.8)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Train vs Test Metric Stability\", fontsize=14, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Save the plot\n",
    "fig.savefig(os.path.join(run_folder, \"train_vs_test_metrics.png\"), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9690a18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
