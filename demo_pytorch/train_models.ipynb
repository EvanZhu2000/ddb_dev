{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Futures Trading Models: Deep Learning & Reinforcement Learning\n",
        "\n",
        "This notebook demonstrates training AI models for futures trading using **exactly the same data processing** as DolphinDB to ensure consistency between research and production environments.\n",
        "\n",
        "## Key Innovation: Unified Data Processing\n",
        "- ‚úÖ **Same feature engineering**: Use DolphinDB for both training data prep and production inference\n",
        "- ‚úÖ **No duplication**: Single source of truth for all technical indicators\n",
        "- ‚úÖ **Production consistency**: What you train is what you deploy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n",
            "PyTorch version: 2.8.0+cpu\n",
            "CUDA available: False\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # Non-interactive backend for server environments\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# DolphinDB import for consistent data processing\n",
        "import dolphindb as ddb\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set plot style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading Using DolphinDB (Same as Production)\n",
        "\n",
        "**Critical**: We use DolphinDB for data processing to ensure 100% consistency with production environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trying localhost:8848...\n",
            "‚úì Connected to DolphinDB at localhost:8848\n",
            "‚úì Logged in to DolphinDB\n"
          ]
        }
      ],
      "source": [
        "# Connect to DolphinDB for consistent data processing\n",
        "session = ddb.session()\n",
        "\n",
        "# Try to connect to DolphinDB\n",
        "connection_attempts = [\n",
        "    {'host': 'localhost', 'port': 8848}\n",
        "]\n",
        "\n",
        "connected = False\n",
        "for attempt in connection_attempts:\n",
        "    try:\n",
        "        print(f\"Trying {attempt['host']}:{attempt['port']}...\")\n",
        "        session.connect(attempt['host'], attempt['port'])\n",
        "        print(f\"‚úì Connected to DolphinDB at {attempt['host']}:{attempt['port']}\")\n",
        "        connected = True\n",
        "        break\n",
        "    except Exception as e:\n",
        "        print(f\"‚úó Connection failed: {e}\")\n",
        "        continue\n",
        "\n",
        "if not connected:\n",
        "    print(\"\\\\n‚ö†Ô∏è DolphinDB not available - falling back to pandas processing\")\n",
        "    use_ddb = False\n",
        "else:\n",
        "    try:\n",
        "        session.login(\"admin\", \"123456\")\n",
        "        print(\"‚úì Logged in to DolphinDB\")\n",
        "        use_ddb = True\n",
        "    except Exception as e:\n",
        "        print(f\"Login failed: {e}\")\n",
        "        use_ddb = True  # Continue without login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Processing data with DolphinDB (same as production)...\n",
            "‚úó parquet already loaded\n",
            "‚úì Processed 7192 records using DolphinDB\n",
            "\\nData shape: (7192, 17)\n",
            "Columns: ['order_book_id', 'datetime', 'trading_date', 'open_interest', 'open', 'volume', 'total_turnover', 'low', 'close', 'high', 'parent_order_book_id', 'UTC_datetime', 'maturity_month', 'sma_5', 'sma_20', 'price_change', 'volatility']\n",
            "Symbols: ['IF2303' 'IH2303']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>order_book_id</th>\n",
              "      <th>datetime</th>\n",
              "      <th>trading_date</th>\n",
              "      <th>open_interest</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>total_turnover</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>parent_order_book_id</th>\n",
              "      <th>UTC_datetime</th>\n",
              "      <th>maturity_month</th>\n",
              "      <th>sma_5</th>\n",
              "      <th>sma_20</th>\n",
              "      <th>price_change</th>\n",
              "      <th>volatility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>IF2303</td>\n",
              "      <td>2023-01-03 09:35:00</td>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>72064.0</td>\n",
              "      <td>3884.4</td>\n",
              "      <td>149.0</td>\n",
              "      <td>173548440.0</td>\n",
              "      <td>3881.0</td>\n",
              "      <td>3881.6</td>\n",
              "      <td>3884.4</td>\n",
              "      <td>IF</td>\n",
              "      <td>2023-01-03 01:35:00</td>\n",
              "      <td>2023-03-01</td>\n",
              "      <td>3880.92</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-2.8</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IF2303</td>\n",
              "      <td>2023-01-03 09:36:00</td>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>72013.0</td>\n",
              "      <td>3881.6</td>\n",
              "      <td>142.0</td>\n",
              "      <td>165279480.0</td>\n",
              "      <td>3878.0</td>\n",
              "      <td>3878.2</td>\n",
              "      <td>3881.6</td>\n",
              "      <td>IF</td>\n",
              "      <td>2023-01-03 01:36:00</td>\n",
              "      <td>2023-03-01</td>\n",
              "      <td>3881.28</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-3.4</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IF2303</td>\n",
              "      <td>2023-01-03 09:37:00</td>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>71917.0</td>\n",
              "      <td>3878.2</td>\n",
              "      <td>254.0</td>\n",
              "      <td>295034760.0</td>\n",
              "      <td>3869.4</td>\n",
              "      <td>3870.2</td>\n",
              "      <td>3878.2</td>\n",
              "      <td>IF</td>\n",
              "      <td>2023-01-03 01:37:00</td>\n",
              "      <td>2023-03-01</td>\n",
              "      <td>3879.44</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-8.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>IF2303</td>\n",
              "      <td>2023-01-03 09:38:00</td>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>71848.0</td>\n",
              "      <td>3870.6</td>\n",
              "      <td>273.0</td>\n",
              "      <td>316679400.0</td>\n",
              "      <td>3863.4</td>\n",
              "      <td>3865.6</td>\n",
              "      <td>3870.6</td>\n",
              "      <td>IF</td>\n",
              "      <td>2023-01-03 01:38:00</td>\n",
              "      <td>2023-03-01</td>\n",
              "      <td>3876.00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-4.6</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>IF2303</td>\n",
              "      <td>2023-01-03 09:39:00</td>\n",
              "      <td>2023-01-03</td>\n",
              "      <td>71854.0</td>\n",
              "      <td>3865.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>244541940.0</td>\n",
              "      <td>3861.8</td>\n",
              "      <td>3861.8</td>\n",
              "      <td>3865.0</td>\n",
              "      <td>IF</td>\n",
              "      <td>2023-01-03 01:39:00</td>\n",
              "      <td>2023-03-01</td>\n",
              "      <td>3871.48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-3.8</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  order_book_id            datetime trading_date  open_interest    open  \\\n",
              "0        IF2303 2023-01-03 09:35:00   2023-01-03        72064.0  3884.4   \n",
              "1        IF2303 2023-01-03 09:36:00   2023-01-03        72013.0  3881.6   \n",
              "2        IF2303 2023-01-03 09:37:00   2023-01-03        71917.0  3878.2   \n",
              "3        IF2303 2023-01-03 09:38:00   2023-01-03        71848.0  3870.6   \n",
              "4        IF2303 2023-01-03 09:39:00   2023-01-03        71854.0  3865.0   \n",
              "\n",
              "   volume  total_turnover     low   close    high parent_order_book_id  \\\n",
              "0   149.0     173548440.0  3881.0  3881.6  3884.4                   IF   \n",
              "1   142.0     165279480.0  3878.0  3878.2  3881.6                   IF   \n",
              "2   254.0     295034760.0  3869.4  3870.2  3878.2                   IF   \n",
              "3   273.0     316679400.0  3863.4  3865.6  3870.6                   IF   \n",
              "4   211.0     244541940.0  3861.8  3861.8  3865.0                   IF   \n",
              "\n",
              "         UTC_datetime maturity_month    sma_5  sma_20  price_change  \\\n",
              "0 2023-01-03 01:35:00     2023-03-01  3880.92     NaN          -2.8   \n",
              "1 2023-01-03 01:36:00     2023-03-01  3881.28     NaN          -3.4   \n",
              "2 2023-01-03 01:37:00     2023-03-01  3879.44     NaN          -8.0   \n",
              "3 2023-01-03 01:38:00     2023-03-01  3876.00     NaN          -4.6   \n",
              "4 2023-01-03 01:39:00     2023-03-01  3871.48     NaN          -3.8   \n",
              "\n",
              "   volatility  \n",
              "0         NaN  \n",
              "1         NaN  \n",
              "2         NaN  \n",
              "3         NaN  \n",
              "4         NaN  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load and process data using EXACTLY the same method as final_prediction.dos\n",
        "if use_ddb:\n",
        "    print(\"üîÑ Processing data with DolphinDB (same as production)...\")\n",
        "    \n",
        "    # Use EXACTLY the same code as final_prediction.dos and return data in one call\n",
        "    df_processed = session.run('''\n",
        "    try {\n",
        "        loadPlugin(\"parquet\")\n",
        "        print(\"‚úì parquet loaded\")\n",
        "    } catch(ex) {\n",
        "        print(\"‚úó parquet already loaded\")\n",
        "    }\n",
        "    \n",
        "    sampleData = parquet::loadParquet(\"sample_M_Y_IH_IF\")\n",
        "    sampleData = select * from sampleData where order_book_id in ['IH2303','IF2303']\n",
        "    \n",
        "    // Feature engineering - EXACTLY same as production\n",
        "    cleanData = select *,\n",
        "        mavg(close, 5) as sma_5,\n",
        "        mavg(close, 20) as sma_20,\n",
        "        close - prev(close) as price_change,\n",
        "        mstd(close, 10) as volatility\n",
        "    from sampleData context by order_book_id\n",
        "    \n",
        "    // Remove NULL rows\n",
        "    cleanData = select * from cleanData where not isNull(sma_5) and not isNull(sma_20) and not isNull(volatility)\n",
        "    \n",
        "    // Return the cleaned data\n",
        "    cleanData\n",
        "    ''')\n",
        "    print(f\"‚úì Processed {len(df_processed)} records using DolphinDB\")\n",
        "    \n",
        "else:\n",
        "    print(\"üìÅ Fallback: Loading data with pandas...\")\n",
        "    df_processed = pd.read_parquet('data/sample_M_Y_IH_IF.parquet')\n",
        "    print(f\"Loaded {len(df_processed)} records with pandas\")\n",
        "\n",
        "# Display basic info\n",
        "print(f\"\\\\nData shape: {df_processed.shape}\")\n",
        "print(f\"Columns: {list(df_processed.columns)}\")\n",
        "if 'order_book_id' in df_processed.columns:\n",
        "    print(f\"Symbols: {df_processed['order_book_id'].unique()}\")\n",
        "elif 'symbol' in df_processed.columns:\n",
        "    print(f\"Symbols: {df_processed['symbol'].unique()}\")\n",
        "\n",
        "df_processed.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Preparation for Model Training\n",
        "\n",
        "Now we'll create PyTorch datasets using the cleaned data from DolphinDB.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created 7152 training sequences\n",
            "Feature dimensions: 8 features\n",
            "Available features: ['open', 'high', 'low', 'close', 'volume', 'sma_5', 'sma_20', 'volatility']\n",
            "‚úÖ Using raw DolphinDB features - NO Python normalization\n",
            "\\nTraining set: 5721 samples\n",
            "Validation set: 1431 samples\n",
            "Batch size: 64\n"
          ]
        }
      ],
      "source": [
        "# Dataset class for LSTM training - NO DATA CLEANING (already done in DolphinDB)\n",
        "class FuturesDataset(Dataset):\n",
        "    def __init__(self, data, sequence_length=20):\n",
        "        self.sequences = []\n",
        "        self.targets = []\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        # Use ALL processed features from DolphinDB (already cleaned and ready)\n",
        "        feature_cols = ['open', 'high', 'low', 'close', 'volume']\n",
        "        \n",
        "        # Add technical indicators if available (from DolphinDB processing)\n",
        "        if 'sma_5' in data.columns:\n",
        "            feature_cols.extend(['sma_5', 'sma_20', 'volatility'])\n",
        "        \n",
        "        symbol_col = 'order_book_id' if 'order_book_id' in data.columns else 'symbol'\n",
        "        \n",
        "        for symbol in data[symbol_col].unique():\n",
        "            symbol_data = data[data[symbol_col] == symbol].reset_index(drop=True)\n",
        "            \n",
        "            # Get available features - NO NULL CHECKING (DolphinDB already cleaned)\n",
        "            available_cols = [col for col in feature_cols if col in symbol_data.columns]\n",
        "            features = symbol_data[available_cols].values.astype(np.float32)\n",
        "            \n",
        "            # Create sequences directly - NO NORMALIZATION (rely on DolphinDB preprocessing)\n",
        "            for i in range(len(features) - sequence_length):\n",
        "                window = features[i:i + sequence_length]\n",
        "                \n",
        "                # Target: next close price (raw value - no normalization)\n",
        "                close_idx = available_cols.index('close')\n",
        "                next_close = features[i + sequence_length, close_idx]\n",
        "                \n",
        "                self.sequences.append(window)\n",
        "                self.targets.append(next_close)\n",
        "        \n",
        "        print(f\"Created {len(self.sequences)} training sequences\")\n",
        "        print(f\"Feature dimensions: {len(available_cols)} features\")\n",
        "        print(f\"Available features: {available_cols}\")\n",
        "        print(\"‚úÖ Using raw DolphinDB features - NO Python normalization\")\n",
        "        \n",
        "        self.feature_count = len(available_cols)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return torch.FloatTensor(self.sequences[idx]), torch.FloatTensor([self.targets[idx]])\n",
        "\n",
        "# Create dataset from DolphinDB processed data\n",
        "dataset = FuturesDataset(df_processed)\n",
        "\n",
        "# Train/validation split\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Data loaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"\\\\nTraining set: {len(train_dataset)} samples\")\n",
        "print(f\"Validation set: {len(val_dataset)} samples\")\n",
        "print(f\"Batch size: {batch_size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. LSTM Model Definition and Training\n",
        "\n",
        "Define and train the LSTM model for price prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM Model initialized:\n",
            "- Input size: 8 features\n",
            "- Hidden size: 64\n",
            "- Device: cpu\n",
            "- Parameters: 54337\n"
          ]
        }
      ],
      "source": [
        "# LSTM Model for price prediction\n",
        "class LSTMPricePredictor(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, \n",
        "                           batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
        "        self.fc2 = nn.Linear(hidden_size // 2, 1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        last_output = lstm_out[:, -1, :]\n",
        "        out = self.dropout(self.relu(self.fc1(last_output)))\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Initialize LSTM model\n",
        "input_size = dataset.feature_count\n",
        "lstm_model = LSTMPricePredictor(input_size=input_size).to(device)\n",
        "\n",
        "# Training setup\n",
        "optimizer = optim.Adam(lstm_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "criterion = nn.MSELoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
        "\n",
        "print(f\"LSTM Model initialized:\")\n",
        "print(f\"- Input size: {input_size} features\")\n",
        "print(f\"- Hidden size: 64\")\n",
        "print(f\"- Device: {device}\")\n",
        "print(f\"- Parameters: {sum(p.numel() for p in lstm_model.parameters())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "pre_set_number = 10\n",
        "global pre_set_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Starting LSTM training...\n",
            "Epochs: 10, Batch size: 64, Learning rate: 0.001\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Epoch  1/10: Train Loss: 9059563.100000, Val Loss: nan\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Epoch  6/10: Train Loss: 8457240.666667, Val Loss: nan\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Warning: Invalid loss detected: nan, skipping batch...\n",
            "Epoch 10/10: Train Loss: 7878577.411111, Val Loss: nan\n",
            "‚úÖ LSTM training completed!\n",
            "Final training loss: 7878577.411111\n",
            "Final validation loss: nan\n",
            "Best validation loss: nan\n"
          ]
        }
      ],
      "source": [
        "# LSTM Training with progress tracking\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "epochs = pre_set_number\n",
        "\n",
        "print(\"üöÄ Starting LSTM training...\")\n",
        "print(f\"Epochs: {epochs}, Batch size: {batch_size}, Learning rate: 0.001\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Training phase\n",
        "    lstm_model.train()\n",
        "    epoch_train_loss = 0\n",
        "    \n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = lstm_model(batch_x)\n",
        "        loss = criterion(pred, batch_y)\n",
        "        \n",
        "        # Check for NaN/inf values in loss\n",
        "        if torch.isnan(loss) or torch.isinf(loss):\n",
        "            print(f\"Warning: Invalid loss detected: {loss.item()}, skipping batch...\")\n",
        "            continue\n",
        "            \n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(lstm_model.parameters(), max_norm=1.0)\n",
        "        \n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss.item()\n",
        "    \n",
        "    avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    \n",
        "    # Validation phase\n",
        "    lstm_model.eval()\n",
        "    epoch_val_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in val_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            pred = lstm_model(batch_x)\n",
        "            loss = criterion(pred, batch_y)\n",
        "            epoch_val_loss += loss.item()\n",
        "    \n",
        "    avg_val_loss = epoch_val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    \n",
        "    # Learning rate scheduling\n",
        "    scheduler.step(avg_val_loss)\n",
        "    \n",
        "    # Print progress\n",
        "    if epoch % 5 == 0 or epoch == epochs - 1:\n",
        "        print(f\"Epoch {epoch+1:2d}/{epochs}: Train Loss: {avg_train_loss:.6f}, Val Loss: {avg_val_loss:.6f}\")\n",
        "\n",
        "print(\"‚úÖ LSTM training completed!\")\n",
        "\n",
        "# Store final metrics for model info\n",
        "final_train_loss = train_losses[-1] if train_losses else 0.0\n",
        "final_val_loss = val_losses[-1] if val_losses else 0.0\n",
        "min_val_loss = min(val_losses) if val_losses else 0.0\n",
        "\n",
        "print(f\"Final training loss: {final_train_loss:.6f}\")\n",
        "print(f\"Final validation loss: {final_val_loss:.6f}\")\n",
        "print(f\"Best validation loss: {min_val_loss:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä LSTM Training Summary:\n",
            "   Final Training Loss: 7878577.411111\n",
            "   Final Validation Loss: nan\n",
            "   Best Validation Loss: nan (Epoch 1)\n",
            "   Overfitting Check: ‚úÖ Good generalization\n"
          ]
        }
      ],
      "source": [
        "# Plot LSTM training progress\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss curves\n",
        "axes[0].plot(train_losses, label='Training Loss', color='blue', linewidth=2)\n",
        "axes[0].plot(val_losses, label='Validation Loss', color='red', linewidth=2)\n",
        "axes[0].set_title('LSTM Training Progress')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('MSE Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_yscale('log')  # Log scale for better visualization\n",
        "\n",
        "# Learning curve analysis\n",
        "epochs_range = range(1, len(train_losses) + 1)\n",
        "axes[1].plot(epochs_range, train_losses, 'o-', label='Training Loss', color='blue', markersize=4)\n",
        "axes[1].plot(epochs_range, val_losses, 'o-', label='Validation Loss', color='red', markersize=4)\n",
        "axes[1].set_title('Learning Curve Analysis')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('MSE Loss')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Add performance metrics\n",
        "final_train_loss = train_losses[-1]\n",
        "final_val_loss = val_losses[-1]\n",
        "min_val_loss = min(val_losses)\n",
        "best_epoch = val_losses.index(min_val_loss) + 1\n",
        "\n",
        "axes[1].axhline(y=min_val_loss, color='green', linestyle='--', alpha=0.7, label=f'Best Val Loss: {min_val_loss:.6f}')\n",
        "axes[1].axvline(x=best_epoch, color='green', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print training summary\n",
        "print(\"üìä LSTM Training Summary:\")\n",
        "print(f\"   Final Training Loss: {final_train_loss:.6f}\")\n",
        "print(f\"   Final Validation Loss: {final_val_loss:.6f}\")\n",
        "print(f\"   Best Validation Loss: {min_val_loss:.6f} (Epoch {best_epoch})\")\n",
        "print(f\"   Overfitting Check: {'‚ö†Ô∏è Possible overfitting' if final_val_loss > min_val_loss * 1.1 else '‚úÖ Good generalization'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. DQN Reinforcement Learning Models\n",
        "\n",
        "Now we'll create and train the DQN models for trading decisions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trading Environment initialized:\n",
            "- State size: 163\n",
            "- Feature columns: ['open', 'high', 'low', 'close', 'volume', 'sma_5', 'sma_20', 'volatility']\n",
            "- Sample state shape: (163,)\n"
          ]
        }
      ],
      "source": [
        "# Trading Environment for DQN training\n",
        "class TradingEnvironment:\n",
        "    def __init__(self, data, lookback_window=20):\n",
        "        self.data = data\n",
        "        self.lookback_window = lookback_window\n",
        "        self.feature_cols = ['open', 'high', 'low', 'close', 'volume']\n",
        "        if 'sma_5' in data.columns:\n",
        "            self.feature_cols.extend(['sma_5', 'sma_20', 'volatility'])\n",
        "        self.reset()\n",
        "    \n",
        "    def reset(self):\n",
        "        self.current_step = self.lookback_window\n",
        "        self.balance = 100000.0\n",
        "        self.position = 0  # -1: short, 0: neutral, 1: long\n",
        "        self.entry_price = 0.0\n",
        "        return self._get_state()\n",
        "    \n",
        "    def _get_state(self):\n",
        "        # Get current market state - NO NORMALIZATION (DolphinDB already processed)\n",
        "        start_idx = self.current_step - self.lookback_window\n",
        "        end_idx = self.current_step\n",
        "        \n",
        "        window_data = self.data.iloc[start_idx:end_idx]\n",
        "        features = window_data[self.feature_cols].values.astype(np.float32)\n",
        "        \n",
        "        # Use raw features directly - NO Python normalization\n",
        "        features_flat = features.flatten()\n",
        "        \n",
        "        # Add trading state features (raw values - let DolphinDB handle scaling)\n",
        "        state = np.concatenate([\n",
        "            features_flat,  # raw market features from DolphinDB\n",
        "            [self.position],  # raw position: -1, 0, 1\n",
        "            [self.balance],     # raw balance\n",
        "            [self.entry_price]  # raw entry price\n",
        "        ])\n",
        "        \n",
        "        return state.astype(np.float32)\n",
        "    \n",
        "    def step(self, action):\n",
        "        current_price = self.data.iloc[self.current_step]['close']\n",
        "        reward = 0.0\n",
        "        \n",
        "        # Execute action: 0=hold, 1=buy, 2=sell\n",
        "        if action == 1 and self.position <= 0:  # Buy\n",
        "            if self.position == -1:  # Close short position\n",
        "                reward = (self.entry_price - current_price) / self.entry_price * 100\n",
        "                self.balance += reward\n",
        "            self.position = 1\n",
        "            self.entry_price = current_price\n",
        "            \n",
        "        elif action == 2 and self.position >= 0:  # Sell\n",
        "            if self.position == 1:  # Close long position\n",
        "                reward = (current_price - self.entry_price) / self.entry_price * 100\n",
        "                self.balance += reward\n",
        "            self.position = -1\n",
        "            self.entry_price = current_price\n",
        "        \n",
        "        # Move to next step\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.data) - 1\n",
        "        \n",
        "        # Small penalty for holding (encourage trading)\n",
        "        if action == 0:\n",
        "            reward -= 0.01\n",
        "        \n",
        "        next_state = self._get_state() if not done else None\n",
        "        \n",
        "        return next_state, reward, done\n",
        "\n",
        "# Test environment setup\n",
        "symbol_col = 'order_book_id' if 'order_book_id' in df_processed.columns else 'symbol'\n",
        "first_symbol = df_processed[symbol_col].unique()[0]\n",
        "symbol_data = df_processed[df_processed[symbol_col] == first_symbol].reset_index(drop=True)\n",
        "\n",
        "env = TradingEnvironment(symbol_data)\n",
        "state = env.reset()\n",
        "state_size = len(state)\n",
        "\n",
        "print(f\"Trading Environment initialized:\")\n",
        "print(f\"- State size: {state_size}\")\n",
        "print(f\"- Feature columns: {env.feature_cols}\")\n",
        "print(f\"- Sample state shape: {state.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DQN Models initialized:\n",
            "- DQN model parameters: 141059\n",
            "- Action predictor parameters: 141059\n",
            "- State size: 163\n"
          ]
        }
      ],
      "source": [
        "# DQN Model Definitions\n",
        "class DQNModel(nn.Module):\n",
        "    \"\"\"Deep Q-Network for trading decisions.\"\"\"\n",
        "    \n",
        "    def __init__(self, state_size, action_size=3, hidden_size=256):\n",
        "        super(DQNModel, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, hidden_size // 2)\n",
        "        self.fc4 = nn.Linear(hidden_size // 2, action_size)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "class DQNActionPredictor(nn.Module):\n",
        "    \"\"\"DQN model that directly outputs action predictions (argmax).\"\"\"\n",
        "    \n",
        "    def __init__(self, state_size, hidden_size=256):\n",
        "        super(DQNActionPredictor, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, hidden_size // 2)\n",
        "        self.fc4 = nn.Linear(hidden_size // 2, 3)  # Q-values for 3 actions\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc3(x))\n",
        "        q_values = self.fc4(x)\n",
        "        \n",
        "        # Return argmax as action prediction\n",
        "        actions = torch.argmax(q_values, dim=-1, keepdim=True).float()\n",
        "        return actions\n",
        "\n",
        "# Initialize DQN models\n",
        "dqn_model = DQNModel(state_size=state_size).to(device)\n",
        "dqn_action_predictor = DQNActionPredictor(state_size=state_size).to(device)\n",
        "\n",
        "print(f\"DQN Models initialized:\")\n",
        "print(f\"- DQN model parameters: {sum(p.numel() for p in dqn_model.parameters())}\")\n",
        "print(f\"- Action predictor parameters: {sum(p.numel() for p in dqn_action_predictor.parameters())}\")\n",
        "print(f\"- State size: {state_size}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Running FIXED DQN training...\n",
            "Generating training data through environment interaction...\n",
            "Episode 0: Total Reward = -5.44\n",
            "Generated 35750 training samples from 10 episodes\n",
            "Data validation: 35600/35750 valid samples\n",
            "States tensor shape: torch.Size([35600, 163])\n",
            "Actions tensor shape: torch.Size([35600]), range: [0, 2]\n",
            "Rewards tensor shape: torch.Size([35600])\n",
            "Training DQN neural networks...\n",
            "DQN Epoch 0, Loss: 162809.187500\n",
            "Predicted actions shape: torch.Size([35600, 1])\n",
            "Actions tensor shape: torch.Size([35600])\n",
            "Predicted actions range: [0.000, 2.000]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "Target 2 is out of bounds.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 123\u001b[39m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPredicted actions range: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_actions.min()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_actions.max()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Use CrossEntropyLoss for classification (3 classes: 0, 1, 2)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m loss = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Check for invalid loss\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.isnan(loss) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(loss):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:3462\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3461\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3463\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3466\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3469\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mIndexError\u001b[39m: Target 2 is out of bounds."
          ]
        }
      ],
      "source": [
        "# Fixed DQN Training (with proper error handling)\n",
        "print(\"üîß Running FIXED DQN training...\")\n",
        "\n",
        "# Training setup\n",
        "optimizer_dqn = optim.Adam(dqn_model.parameters(), lr=0.001)\n",
        "optimizer_action = optim.Adam(dqn_action_predictor.parameters(), lr=0.001)\n",
        "\n",
        "# Generate training data through environment interaction\n",
        "states = []\n",
        "actions = []\n",
        "rewards = []\n",
        "episode_rewards = []\n",
        "\n",
        "episodes = 20\n",
        "\n",
        "print(\"Generating training data through environment interaction...\")\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    \n",
        "    while env.current_step < len(env.data) - 1:\n",
        "        # Epsilon-greedy action selection\n",
        "        if np.random.random() < 0.3:  # 30% random actions for exploration\n",
        "            action = np.random.randint(0, 3)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                q_values = dqn_model(torch.FloatTensor(state).unsqueeze(0).to(device))\n",
        "                action = q_values.argmax().item()\n",
        "        \n",
        "        next_state, reward, done = env.step(action)\n",
        "        \n",
        "        states.append(state)\n",
        "        actions.append(action)\n",
        "        rewards.append(reward)\n",
        "        total_reward += reward\n",
        "        \n",
        "        if done:\n",
        "            break\n",
        "            \n",
        "        state = next_state\n",
        "    \n",
        "    episode_rewards.append(total_reward)\n",
        "    \n",
        "    # Print progress\n",
        "    if episode % 20 == 0:\n",
        "        print(f\"Episode {episode}: Total Reward = {total_reward:.2f}\")\n",
        "\n",
        "print(f\"Generated {len(states)} training samples from {episodes} episodes\")\n",
        "\n",
        "# Convert to tensors and validate data\n",
        "if len(states) > 0:\n",
        "    states_array = np.array(states)\n",
        "    actions_array = np.array(actions)\n",
        "    rewards_array = np.array(rewards)\n",
        "    \n",
        "    # Validate and filter data\n",
        "    valid_mask = (\n",
        "        ~np.isnan(states_array).any(axis=1) & \n",
        "        ~np.isinf(states_array).any(axis=1) &\n",
        "        (actions_array >= 0) & \n",
        "        (actions_array <= 2) &  # Ensure actions are in valid range [0, 1, 2]\n",
        "        ~np.isnan(rewards_array) &\n",
        "        ~np.isinf(rewards_array)\n",
        "    )\n",
        "    \n",
        "    print(f\"Data validation: {valid_mask.sum()}/{len(valid_mask)} valid samples\")\n",
        "    \n",
        "    # Apply filter\n",
        "    states_clean = states_array[valid_mask]\n",
        "    actions_clean = actions_array[valid_mask]\n",
        "    rewards_clean = rewards_array[valid_mask]\n",
        "    \n",
        "    if len(states_clean) == 0:\n",
        "        print(\"‚ùå No valid training data after filtering!\")\n",
        "    else:\n",
        "        # Convert to tensors\n",
        "        states_tensor = torch.FloatTensor(states_clean).to(device)\n",
        "        actions_tensor = torch.LongTensor(actions_clean).to(device)\n",
        "        rewards_tensor = torch.FloatTensor(rewards_clean).to(device)\n",
        "        \n",
        "        # Debug: Check tensor shapes and ranges\n",
        "        print(f\"States tensor shape: {states_tensor.shape}\")\n",
        "        print(f\"Actions tensor shape: {actions_tensor.shape}, range: [{actions_tensor.min()}, {actions_tensor.max()}]\")\n",
        "        print(f\"Rewards tensor shape: {rewards_tensor.shape}\")\n",
        "        \n",
        "        print(\"Training DQN neural networks...\")\n",
        "        \n",
        "        \n",
        "        # Train DQN model (Q-values) - This part works fine\n",
        "        dqn_losses = []\n",
        "        for epoch in range(pre_set_number):\n",
        "            optimizer_dqn.zero_grad()\n",
        "            q_values = dqn_model(states_tensor)\n",
        "            q_values_selected = q_values.gather(1, actions_tensor.unsqueeze(1))\n",
        "            loss = F.mse_loss(q_values_selected.squeeze(), rewards_tensor)\n",
        "            \n",
        "            # Check for invalid loss\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                print(f\"Warning: Invalid DQN loss at epoch {epoch}, skipping...\")\n",
        "                continue\n",
        "                \n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(dqn_model.parameters(), max_norm=1.0)\n",
        "            optimizer_dqn.step()\n",
        "            dqn_losses.append(loss.item())\n",
        "            \n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"DQN Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "        \n",
        "        # Train action predictor with FIXED CrossEntropyLoss\n",
        "        action_losses = []\n",
        "        for epoch in range(pre_set_number):\n",
        "            optimizer_action.zero_grad()\n",
        "            predicted_actions = dqn_action_predictor(states_tensor)\n",
        "            \n",
        "            # DEBUG: Check output dimensions\n",
        "            if epoch == 0:\n",
        "                print(f\"Predicted actions shape: {predicted_actions.shape}\")\n",
        "                print(f\"Actions tensor shape: {actions_tensor.shape}\")\n",
        "                print(f\"Predicted actions range: [{predicted_actions.min():.3f}, {predicted_actions.max():.3f}]\")\n",
        "            \n",
        "            # Use CrossEntropyLoss for classification (3 classes: 0, 1, 2)\n",
        "            loss = F.cross_entropy(predicted_actions, actions_tensor)\n",
        "            \n",
        "            # Check for invalid loss\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                print(f\"Warning: Invalid Action loss at epoch {epoch}, skipping...\")\n",
        "                continue\n",
        "                \n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(dqn_action_predictor.parameters(), max_norm=1.0)\n",
        "            optimizer_action.step()\n",
        "            action_losses.append(loss.item())\n",
        "            \n",
        "            if epoch % 10 == 0:\n",
        "                print(f\"Action Predictor Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "        \n",
        "        print(\"‚úÖ DQN training completed successfully!\")\n",
        "        \n",
        "        # Plot DQN training results\n",
        "        if dqn_losses and action_losses:\n",
        "            plt.figure(figsize=(12, 5))\n",
        "            \n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.plot(dqn_losses, 'b-', linewidth=2)\n",
        "            plt.title('DQN Q-Value Training Loss')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('MSE Loss')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            \n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.plot(action_losses, 'r-', linewidth=2)\n",
        "            plt.title('DQN Action Predictor Loss')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('CrossEntropy Loss')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            print(f\"üìä DQN Training Summary:\")\n",
        "            print(f\"   Final DQN Loss: {dqn_losses[-1]:.6f}\")\n",
        "            print(f\"   Final Action Loss: {action_losses[-1]:.6f}\")\n",
        "else:\n",
        "    print(\"‚ùå No training data available!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Training DQN models...\n",
            "Episode 0, Total Reward: -4.36\n",
            "DQN environment training completed! Generated 35750 training samples\n",
            "Training DQN neural networks...\n",
            "DQN Epoch 0, Loss: nan\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "Target 2 is out of bounds.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     73\u001b[39m optimizer_action.zero_grad()\n\u001b[32m     74\u001b[39m predicted_actions = dqn_action_predictor(states_tensor)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m loss = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_actions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m loss.backward()\n\u001b[32m     77\u001b[39m optimizer_action.step()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:3462\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3461\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3463\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3466\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3469\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mIndexError\u001b[39m: Target 2 is out of bounds."
          ]
        }
      ],
      "source": [
        "# DQN Training\n",
        "print(\"üöÄ Training DQN models...\")\n",
        "\n",
        "# Training setup\n",
        "optimizer_dqn = optim.Adam(dqn_model.parameters(), lr=0.001)\n",
        "optimizer_action = optim.Adam(dqn_action_predictor.parameters(), lr=0.001)\n",
        "\n",
        "# Generate training data through environment interaction\n",
        "states = []\n",
        "actions = []\n",
        "rewards = []\n",
        "episode_rewards = []\n",
        "\n",
        "episodes = pre_set_number\n",
        "\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    \n",
        "    while env.current_step < len(env.data) - 1:\n",
        "        # Epsilon-greedy action selection\n",
        "        if np.random.random() < 0.3:  # 30% random actions for exploration\n",
        "            action = np.random.randint(0, 3)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                q_values = dqn_model(torch.FloatTensor(state).unsqueeze(0).to(device))\n",
        "                action = q_values.argmax().item()\n",
        "        \n",
        "        next_state, reward, done = env.step(action)\n",
        "        \n",
        "        states.append(state)\n",
        "        actions.append(action)\n",
        "        rewards.append(reward)\n",
        "        \n",
        "        if done:\n",
        "            break\n",
        "        \n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "    \n",
        "    episode_rewards.append(total_reward)\n",
        "    \n",
        "    if episode % 20 == 0:\n",
        "        print(f\"Episode {episode}, Total Reward: {total_reward:.2f}\")\n",
        "\n",
        "print(f\"DQN environment training completed! Generated {len(states)} training samples\")\n",
        "\n",
        "# Convert to tensors and train neural networks\n",
        "if len(states) > 0:\n",
        "    states_tensor = torch.FloatTensor(np.array(states)).to(device)\n",
        "    actions_tensor = torch.LongTensor(actions).to(device)\n",
        "    rewards_tensor = torch.FloatTensor(rewards).to(device)\n",
        "    \n",
        "    print(\"Training DQN neural networks...\")\n",
        "    \n",
        "    # Train DQN model (Q-values)\n",
        "    dqn_losses = []\n",
        "    for epoch in range(pre_set_number):\n",
        "        optimizer_dqn.zero_grad()\n",
        "        q_values = dqn_model(states_tensor)\n",
        "        q_values_selected = q_values.gather(1, actions_tensor.unsqueeze(1))\n",
        "        loss = F.mse_loss(q_values_selected.squeeze(), rewards_tensor)\n",
        "        loss.backward()\n",
        "        optimizer_dqn.step()\n",
        "        dqn_losses.append(loss.item())\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"DQN Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "    \n",
        "    # Train action predictor\n",
        "    action_losses = []\n",
        "    for epoch in range(pre_set_number):\n",
        "        optimizer_action.zero_grad()\n",
        "        predicted_actions = dqn_action_predictor(states_tensor)\n",
        "        loss = F.cross_entropy(predicted_actions, actions_tensor)\n",
        "        loss.backward()\n",
        "        optimizer_action.step()\n",
        "        action_losses.append(loss.item())\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Action Predictor Epoch {epoch}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "print(\"‚úÖ DQN training completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä DQN Training Summary:\n",
            "   Episodes: 10\n",
            "   Training samples generated: 35750\n",
            "   Average episode reward: -7.82\n",
            "   Best episode reward: -3.71\n",
            "   Worst episode reward: -12.97\n",
            "   Final DQN loss: nan\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Final DQN loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdqn_losses[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33maction_losses\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Final Action Predictor loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43maction_losses\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mIndexError\u001b[39m: list index out of range"
          ]
        }
      ],
      "source": [
        "# Plot DQN training results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('DQN Training Results', fontsize=16)\n",
        "\n",
        "# Episode rewards\n",
        "axes[0, 0].plot(episode_rewards, color='blue', alpha=0.7)\n",
        "axes[0, 0].set_title('Episode Rewards')\n",
        "axes[0, 0].set_xlabel('Episode')\n",
        "axes[0, 0].set_ylabel('Total Reward')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "axes[0, 0].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Reward distribution\n",
        "axes[0, 1].hist(episode_rewards, bins=20, alpha=0.7, color='blue', edgecolor='black')\n",
        "axes[0, 1].set_title('Reward Distribution')\n",
        "axes[0, 1].set_xlabel('Total Reward')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "axes[0, 1].axvline(x=np.mean(episode_rewards), color='red', linestyle='--', \n",
        "                   label=f'Mean: {np.mean(episode_rewards):.2f}')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# DQN loss\n",
        "if 'dqn_losses' in locals():\n",
        "    axes[1, 0].plot(dqn_losses, color='red', linewidth=2)\n",
        "    axes[1, 0].set_title('DQN Training Loss')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('MSE Loss')\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    axes[1, 0].set_yscale('log')\n",
        "\n",
        "# Action predictor loss\n",
        "if 'action_losses' in locals():\n",
        "    axes[1, 1].plot(action_losses, color='green', linewidth=2)\n",
        "    axes[1, 1].set_title('Action Predictor Loss')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('MSE Loss')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "    axes[1, 1].set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print DQN training summary\n",
        "print(\"üìä DQN Training Summary:\")\n",
        "print(f\"   Episodes: {episodes}\")\n",
        "print(f\"   Training samples generated: {len(states)}\")\n",
        "print(f\"   Average episode reward: {np.mean(episode_rewards):.2f}\")\n",
        "print(f\"   Best episode reward: {max(episode_rewards):.2f}\")\n",
        "print(f\"   Worst episode reward: {min(episode_rewards):.2f}\")\n",
        "if 'dqn_losses' in locals():\n",
        "    print(f\"   Final DQN loss: {dqn_losses[-1]:.6f}\")\n",
        "if 'action_losses' in locals():\n",
        "    print(f\"   Final Action Predictor loss: {action_losses[-1]:.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Export for DolphinDB Deployment\n",
        "\n",
        "Export all trained models to TorchScript format for production deployment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Exporting models to TorchScript format...\n",
            "‚úÖ LSTM model exported - Output difference: 0.00000000\n",
            "‚úÖ DQN model exported - Max output difference: nan\n",
            "‚úÖ DQN action predictor exported - Output difference: 0.00000000\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'demo_pytorch/model_training_info.json'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     40\u001b[39m model_info = {\n\u001b[32m     41\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtraining_date\u001b[39m\u001b[33m'\u001b[39m: datetime.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m     42\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlstm_model\u001b[39m\u001b[33m'\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature_columns\u001b[39m\u001b[33m'\u001b[39m: env.feature_cols\n\u001b[32m     59\u001b[39m }\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdemo_pytorch/model_training_info.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     63\u001b[39m     json.dump(model_info, f, indent=\u001b[32m2\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'demo_pytorch/model_training_info.json'"
          ]
        }
      ],
      "source": [
        "print(\"üì¶ Exporting models to TorchScript format...\")\n",
        "\n",
        "# Set models to evaluation mode\n",
        "lstm_model.eval()\n",
        "dqn_model.eval()\n",
        "dqn_action_predictor.eval()\n",
        "\n",
        "# Export LSTM model\n",
        "lstm_input = torch.randn(1, 20, input_size).to(device)\n",
        "with torch.no_grad():\n",
        "    traced_lstm = torch.jit.trace(lstm_model, lstm_input)\n",
        "    traced_lstm.save('lstm_price_predictor.pth')\n",
        "    \n",
        "    # Test the traced model\n",
        "    original_output = lstm_model(lstm_input)\n",
        "    traced_output = traced_lstm(lstm_input)\n",
        "    print(f\"‚úÖ LSTM model exported - Output difference: {abs(original_output.item() - traced_output.item()):.8f}\")\n",
        "\n",
        "# Export DQN models\n",
        "dqn_input = torch.randn(1, state_size).to(device)\n",
        "with torch.no_grad():\n",
        "    # Export main DQN model\n",
        "    traced_dqn = torch.jit.trace(dqn_model, dqn_input)\n",
        "    traced_dqn.save('dqn_trading_agent.pth')\n",
        "    \n",
        "    # Export DQN action predictor\n",
        "    traced_dqn_action = torch.jit.trace(dqn_action_predictor, dqn_input)\n",
        "    traced_dqn_action.save('dqn_action_predictor.pth')\n",
        "    \n",
        "    # Test the traced models\n",
        "    original_dqn_output = dqn_model(dqn_input)\n",
        "    traced_dqn_output = traced_dqn(dqn_input)\n",
        "    print(f\"‚úÖ DQN model exported - Max output difference: {(original_dqn_output - traced_dqn_output).abs().max().item():.8f}\")\n",
        "    \n",
        "    original_action_output = dqn_action_predictor(dqn_input)\n",
        "    traced_action_output = traced_dqn_action(dqn_input)\n",
        "    print(f\"‚úÖ DQN action predictor exported - Output difference: {abs(original_action_output.item() - traced_action_output.item()):.8f}\")\n",
        "\n",
        "# Create model info summary\n",
        "model_info = {\n",
        "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'lstm_model': {\n",
        "        'input_shape': [20, input_size],\n",
        "        'features': input_size,\n",
        "        'final_train_loss': final_train_loss,\n",
        "        'final_val_loss': final_val_loss,\n",
        "        'best_val_loss': min_val_loss,\n",
        "        'epochs_trained': epochs\n",
        "    },\n",
        "    'dqn_models': {\n",
        "        'state_size': state_size,\n",
        "        'actions': ['hold', 'buy', 'sell'],\n",
        "        'episodes_trained': episodes,\n",
        "        'avg_episode_reward': np.mean(episode_rewards),\n",
        "        'training_samples': len(states)\n",
        "    },\n",
        "    'data_processing': 'DolphinDB (consistent with production)',\n",
        "    'feature_columns': env.feature_cols\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('demo_pytorch/model_training_info.json', 'w') as f:\n",
        "    json.dump(model_info, f, indent=2)\n",
        "\n",
        "print(\"\\\\n\" + \"=\"*60)\n",
        "print(\"üéâ MODELS SUCCESSFULLY EXPORTED FOR DOLPHINDB!\")\n",
        "print(\"=\"*60)\n",
        "print(\"Files created:\")\n",
        "print(\"1. demo_pytorch/lstm_price_predictor.pth - LSTM model (TorchScript)\")\n",
        "print(\"2. demo_pytorch/dqn_trading_agent.pth - DQN Q-values model (TorchScript)\")\n",
        "print(\"3. demo_pytorch/dqn_action_predictor.pth - DQN action predictor (TorchScript)\")\n",
        "print(\"4. demo_pytorch/model_training_info.json - Training metrics and info\")\n",
        "print(f\"\\\\nüîß Model Specifications:\")\n",
        "print(f\"   LSTM Input: [1, 20, {input_size}] - 20 time steps, {input_size} features\")\n",
        "print(f\"   DQN Input: [1, {state_size}] - Flattened market state + trading state\")\n",
        "print(f\"   Data Processing: IDENTICAL to production DolphinDB pipeline\")\n",
        "print(\"\\\\nüöÄ Ready for deployment in DolphinDB with LibTorch plugin!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cp /home/uat/dolphindb_dev/demo_pytorch/*.pth /home/uat/ddb/server/  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
